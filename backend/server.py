from fastapi import FastAPI, APIRouter, HTTPException, UploadFile, File, Form, Header
from fastapi.staticfiles import StaticFiles
from dotenv import load_dotenv
from starlette.middleware.cors import CORSMiddleware
from motor.motor_asyncio import AsyncIOMotorClient
import os
import logging
from pathlib import Path
from pydantic import BaseModel, Field, ConfigDict
from typing import List, Optional
import uuid
from datetime import datetime, timezone
import base64
import tempfile
from emergentintegrations.llm.chat import LlmChat, UserMessage, ImageContent
from emergentintegrations.llm.openai.image_generation import OpenAIImageGeneration
from image_annotator import ChartAnnotator


ROOT_DIR = Path(__file__).parent
load_dotenv(ROOT_DIR / '.env')

# Use tempfile for uploads to avoid disk bloat
UPLOAD_FOLDER = tempfile.gettempdir()

# MongoDB connection
mongo_url = os.environ['MONGO_URL']
client = AsyncIOMotorClient(mongo_url)
db = client[os.environ['DB_NAME']]

# Create the main app without a prefix
app = FastAPI()

# Create a router with the /api prefix
api_router = APIRouter(prefix="/api")


# Define Models
class Message(BaseModel):
    model_config = ConfigDict(extra="ignore")
    
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    role: str  # 'user' or 'assistant'
    content: str
    image_urls: Optional[List[str]] = None
    annotated_image_urls: Optional[List[str]] = None
    call_annotated_urls: Optional[List[str]] = None
    put_annotated_urls: Optional[List[str]] = None
    timestamp: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))

class ChatRequest(BaseModel):
    message: str

class ChatResponse(BaseModel):
    user_message: Message
    assistant_message: Message

class ImageAnalysisResponse(BaseModel):
    image_id: str
    image_path: str
    annotated_image_path: Optional[str] = None
    call_annotated_path: Optional[str] = None
    put_annotated_path: Optional[str] = None
    user_message: Message
    assistant_message: Message

class MultipleImagesAnalysisResponse(BaseModel):
    image_ids: List[str]
    image_paths: List[str]
    annotated_image_paths: Optional[List[str]] = None
    call_annotated_paths: Optional[List[str]] = None
    put_annotated_paths: Optional[List[str]] = None
    user_message: Message
    assistant_message: Message

class ImageGenerationRequest(BaseModel):
    prompt: str
    number_of_images: int = 1

class ImageGenerationResponse(BaseModel):
    image_id: str
    image_path: str
    image_base64: str
    user_message: Message
    assistant_message: Message


# Chat endpoint
@api_router.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest, x_custom_api_key: Optional[str] = Header(None)):
    try:
        # Use custom API key if provided, otherwise use Emergent key
        api_key = x_custom_api_key if x_custom_api_key else os.environ['EMERGENT_LLM_KEY']
        
        # Create user message
        user_message = Message(
            role="user",
            content=request.message
        )
        
        # Save user message to database
        user_doc = user_message.model_dump()
        user_doc['timestamp'] = user_doc['timestamp'].isoformat()
        await db.messages.insert_one(user_doc)
        
        # Initialize LLM chat
        chat_client = LlmChat(
            api_key=api_key,
            session_id="chat-session",
            system_message="VocÃª Ã© um assistente Ãºtil e amigÃ¡vel. Responda em portuguÃªs de forma clara e concisa."
        )
        chat_client.with_model("openai", "gpt-5.1")
        
        # Send message to AI
        user_msg = UserMessage(text=request.message)
        ai_response = await chat_client.send_message(user_msg)
        
        # Create assistant message
        assistant_message = Message(
            role="assistant",
            content=ai_response
        )
        
        # Save assistant message to database
        assistant_doc = assistant_message.model_dump()
        assistant_doc['timestamp'] = assistant_doc['timestamp'].isoformat()
        await db.messages.insert_one(assistant_doc)
        
        return ChatResponse(
            user_message=user_message,
            assistant_message=assistant_message
        )
        
    except Exception as e:
        error_msg = str(e)
        logging.error(f"Error in chat endpoint: {error_msg}")
        
        # Check if it's a budget error
        if "Budget has been exceeded" in error_msg or "budget" in error_msg.lower():
            raise HTTPException(
                status_code=402,  # Payment Required
                detail="âŒ OrÃ§amento da chave LLM excedido! Por favor, adicione crÃ©ditos em Profile -> Universal Key -> Add Balance"
            )
        
        raise HTTPException(status_code=500, detail=f"Error processing chat: {error_msg}")


# Image analysis endpoint
@api_router.post("/chat/image", response_model=ImageAnalysisResponse)
async def analyze_image(
    file: UploadFile = File(...),
    question: str = Form(default="FaÃ§a uma anÃ¡lise tÃ©cnica completa deste grÃ¡fico: identifique o ativo, timeframe, tendÃªncia, padrÃµes de candlestick, nÃ­veis de suporte/resistÃªncia, indicadores visÃ­veis, e forneÃ§a projeÃ§Ãµes com estimativas de prÃ³ximos movimentos, incluindo probabilidades e recomendaÃ§Ãµes de entrada (COMPRA/VENDA) com nÃ­veis de stop loss e take profit."),
    x_custom_api_key: Optional[str] = Header(None)
):
    try:
        # Use custom API key if provided
        api_key = x_custom_api_key if x_custom_api_key else os.environ['EMERGENT_LLM_KEY']
        
        # Validate file type
        if not file.content_type or not file.content_type.startswith("image/"):
            raise HTTPException(status_code=400, detail="Arquivo nÃ£o Ã© uma imagem vÃ¡lida")
        
        # Read image
        image_bytes = await file.read()
        
        # Validate image is not empty
        if len(image_bytes) == 0:
            raise HTTPException(status_code=400, detail="Imagem estÃ¡ vazia")
        
        # Convert to base64
        image_base64 = base64.b64encode(image_bytes).decode("utf-8")
        
        # Save image locally
        os.makedirs("uploads", exist_ok=True)
        image_id = str(uuid.uuid4())
        image_filename = f"{image_id}_{file.filename}"
        image_path = f"uploads/{image_filename}"
        
        with open(image_path, "wb") as f:
            f.write(image_bytes)
        
        # Create user message with image
        user_message = Message(
            role="user",
            content=question,
            image_urls=[f"/api/uploads/{image_filename}"]
        )
        
        # Save user message to database
        user_doc = user_message.model_dump()
        user_doc['timestamp'] = user_doc['timestamp'].isoformat()
        await db.messages.insert_one(user_doc)
        
        # Initialize LLM chat with vision model
        chat_client = LlmChat(
            api_key=api_key,
            session_id="vision-session",
            system_message="""VocÃª Ã© um analista tÃ©cnico profissional especializado em anÃ¡lise de grÃ¡ficos de trading e mercado financeiro.

INSTRUÃ‡Ã•ES PARA ANÃLISE DE GRÃFICOS:

1. IDENTIFICAÃ‡ÃƒO DO ATIVO E TIMEFRAME:
   - Identifique o par/ativo sendo negociado (ex: EUR/USD, BTC/USD, etc.)
   - Determine o timeframe do grÃ¡fico (ex: M1, M5, M15, H1, H4, D1)
   - Anote o horÃ¡rio atual e preÃ§o atual

2. ANÃLISE TÃ‰CNICA COMPLETA:
   - **TendÃªncia Principal**: Identifique se estÃ¡ em tendÃªncia de alta, baixa ou lateral
   - **PadrÃµes de Candlestick**: Identifique padrÃµes (Doji, Hammer, Engulfing, etc.)
   - **NÃ­veis de Suporte e ResistÃªncia**: Marque os nÃ­veis-chave onde o preÃ§o reagiu
   - **Estrutura de Mercado**: Identifique topos e fundos, rompimentos, pullbacks
   - **Volume**: Observe se hÃ¡ indicadores de volume e o que indicam

3. INDICADORES TÃ‰CNICOS (se visÃ­veis):
   - MÃ©dias MÃ³veis (posiÃ§Ã£o e cruzamentos)
   - RSI (sobrecompra/sobrevenda)
   - MACD (divergÃªncias e cruzamentos)
   - Bandas de Bollinger
   - Fibonacci (retraÃ§Ãµes e extensÃµes)
   - Outros indicadores visÃ­veis

4. ANÃLISE DO MOMENTUM:
   - Determine se o momentum Ã© forte, fraco ou neutro
   - Identifique divergÃªncias entre preÃ§o e indicadores
   - Avalie a forÃ§a da tendÃªncia atual

5. PROJEÃ‡Ã•ES E ESTIMATIVAS:
   - **PrÃ³xima ResistÃªncia/Suporte**: Onde o preÃ§o provavelmente reagirÃ¡
   - **CenÃ¡rios PossÃ­veis**: 
     * CenÃ¡rio Alta: PrÃ³ximos alvos, condiÃ§Ãµes necessÃ¡rias
     * CenÃ¡rio Baixa: PrÃ³ximos alvos, condiÃ§Ãµes necessÃ¡rias
     * CenÃ¡rio Lateral: Faixas de consolidaÃ§Ã£o
   - **Probabilidade**: Estime probabilidades baseadas na anÃ¡lise tÃ©cnica
   - **Stop Loss e Take Profit**: Sugira nÃ­veis prudentes

6. SINAIS DE ENTRADA (se solicitado):
   - CondiÃ§Ãµes para entrada COMPRA (CALL/BUY)
   - CondiÃ§Ãµes para entrada VENDA (PUT/SELL)
   - Timeframe recomendado para a operaÃ§Ã£o
   - GestÃ£o de risco (% do capital)

7. CONTEXTO DE MERCADO:
   - Identifique se estamos perto de aberturas/fechamentos importantes
   - Note qualquer evento econÃ´mico relevante (se visÃ­vel)
   - Avalie a volatilidade atual

8. CONCLUSÃƒO E RECOMENDAÃ‡Ã•ES:
   - Resuma a anÃ¡lise em 3-4 pontos principais
   - DÃª uma recomendaÃ§Ã£o clara (COMPRA, VENDA, ou AGUARDAR)
   - Indique o nÃ­vel de confianÃ§a da anÃ¡lise (%)
   - Destaque os principais riscos

FORMATO DA RESPOSTA:
Use markdown com seÃ§Ãµes claras, bullet points, e **destaque** para informaÃ§Ãµes importantes.
Seja especÃ­fico com nÃºmeros (preÃ§os, percentuais, timeframes).
ForneÃ§a anÃ¡lise profunda como um analista tÃ©cnico experiente faria.

Responda SEMPRE em portuguÃªs brasileiro de forma profissional e detalhada."""
        )
        chat_client.with_model("openai", "gpt-5.1")
        
        # Create image content
        image_content = ImageContent(image_base64=image_base64)
        
        # Send message with image to AI
        user_msg = UserMessage(
            text=question,
            file_contents=[image_content]
        )
        ai_response = await chat_client.send_message(user_msg)
        
        # Generate annotated images for both CALL and PUT scenarios
        annotated_image_path = None
        call_annotated_path = None
        put_annotated_path = None
        annotated_filename = None
        
        try:
            annotator = ChartAnnotator()
            signals = annotator.extract_trading_signals(ai_response)
            
            # Always generate both CALL and PUT scenario images
            call_bytes, put_bytes = annotator.generate_both_scenarios(image_bytes, ai_response)
            
            # Save CALL annotated image
            call_filename = f"{image_id}_call.png"
            call_annotated_path = f"uploads/{call_filename}"
            with open(call_annotated_path, "wb") as f:
                f.write(call_bytes)
            logging.info(f"Generated CALL annotated image: {call_annotated_path}")
            
            # Save PUT annotated image
            put_filename = f"{image_id}_put.png"
            put_annotated_path = f"uploads/{put_filename}"
            with open(put_annotated_path, "wb") as f:
                f.write(put_bytes)
            logging.info(f"Generated PUT annotated image: {put_annotated_path}")
            
            # Set the main annotated image based on detected action
            if signals['action'] == 'CALL':
                annotated_filename = call_filename
                annotated_image_path = call_annotated_path
            elif signals['action'] == 'PUT':
                annotated_filename = put_filename
                annotated_image_path = put_annotated_path
            else:
                # Default to CALL if no clear signal
                annotated_filename = call_filename
                annotated_image_path = call_annotated_path
                
        except Exception as e:
            logging.error(f"Error generating annotated images: {str(e)}")
            import traceback
            logging.error(traceback.format_exc())
            # Continue without annotated images
        
        # Create assistant message
        assistant_message = Message(
            role="assistant",
            content=ai_response
        )
        
        # Save assistant message to database
        assistant_doc = assistant_message.model_dump()
        assistant_doc['timestamp'] = assistant_doc['timestamp'].isoformat()
        await db.messages.insert_one(assistant_doc)
        
        return ImageAnalysisResponse(
            image_id=image_id,
            image_path=image_path,
            annotated_image_path=f"/api/uploads/{annotated_filename}" if annotated_image_path else None,
            call_annotated_path=f"/api/uploads/{call_filename}" if call_annotated_path else None,
            put_annotated_path=f"/api/uploads/{put_filename}" if put_annotated_path else None,
            user_message=user_message,
            assistant_message=assistant_message
        )
        
    except HTTPException:
        raise
    except Exception as e:
        error_msg = str(e)
        logging.error(f"Error in image analysis endpoint: {error_msg}")
        
        # Check if it's a budget error
        if "Budget has been exceeded" in error_msg or "budget" in error_msg.lower():
            raise HTTPException(
                status_code=402,  # Payment Required
                detail="âŒ OrÃ§amento da chave LLM excedido! Por favor, adicione crÃ©ditos em Profile -> Universal Key -> Add Balance"
            )
        
        raise HTTPException(status_code=500, detail=f"Error analyzing image: {error_msg}")


# Multiple images analysis endpoint
@api_router.post("/chat/images", response_model=MultipleImagesAnalysisResponse)
async def analyze_multiple_images(
    files: List[UploadFile] = File(...),
    question: str = Form(default="FaÃ§a uma anÃ¡lise tÃ©cnica completa comparativa destes grÃ¡ficos: para cada imagem, identifique o ativo, timeframe, tendÃªncia, padrÃµes, nÃ­veis chave, e forneÃ§a uma anÃ¡lise consolidada com recomendaÃ§Ãµes gerais considerando todos os grÃ¡ficos."),
    x_custom_api_key: Optional[str] = Header(None)
):
    try:
        # Use custom API key if provided
        api_key = x_custom_api_key if x_custom_api_key else os.environ['EMERGENT_LLM_KEY']
        
        if not files or len(files) == 0:
            raise HTTPException(status_code=400, detail="Nenhuma imagem foi enviada")
        
        # Validate all files are images
        for file in files:
            if not file.content_type or not file.content_type.startswith("image/"):
                raise HTTPException(status_code=400, detail=f"Arquivo {file.filename} nÃ£o Ã© uma imagem vÃ¡lida")
        
        image_ids = []
        image_paths = []
        image_contents = []
        image_urls = []
        original_image_bytes = []  # Store original bytes for annotation
        
        # Process all images
        for file in files:
            # Read image
            image_bytes = await file.read()
            
            # Validate image is not empty
            if len(image_bytes) == 0:
                raise HTTPException(status_code=400, detail=f"Imagem {file.filename} estÃ¡ vazia")
            
            # Store original bytes
            original_image_bytes.append(image_bytes)
            
            # Convert to base64
            image_base64 = base64.b64encode(image_bytes).decode("utf-8")
            
            # Save image locally
            os.makedirs("uploads", exist_ok=True)
            image_id = str(uuid.uuid4())
            image_filename = f"{image_id}_{file.filename}"
            image_path = f"uploads/{image_filename}"
            
            with open(image_path, "wb") as f:
                f.write(image_bytes)
            
            image_ids.append(image_id)
            image_paths.append(image_path)
            image_urls.append(f"/api/uploads/{image_filename}")
            
            # Create image content for AI
            image_content = ImageContent(image_base64=image_base64)
            image_contents.append(image_content)
        
        # Create user message with multiple images
        user_message = Message(
            role="user",
            content=question,
            image_urls=image_urls
        )
        
        # Save user message to database
        user_doc = user_message.model_dump()
        user_doc['timestamp'] = user_doc['timestamp'].isoformat()
        await db.messages.insert_one(user_doc)
        
        # Initialize LLM chat with vision model
        chat_client = LlmChat(
            api_key=api_key,
            session_id="vision-multiple-session",
            system_message="""VocÃª Ã© um analista tÃ©cnico profissional especializado em anÃ¡lise comparativa de mÃºltiplos grÃ¡ficos de trading.

INSTRUÃ‡Ã•ES PARA ANÃLISE DE MÃšLTIPLOS GRÃFICOS:

1. Para cada imagem/grÃ¡fico recebido:
   - Identifique o ativo, timeframe, preÃ§o atual
   - FaÃ§a uma anÃ¡lise tÃ©cnica individual resumida

2. AnÃ¡lise Comparativa:
   - Compare tendÃªncias entre os diferentes ativos/timeframes
   - Identifique correlaÃ§Ãµes ou divergÃªncias
   - Note diferenÃ§as significativas em forÃ§a de tendÃªncia

3. SÃ­ntese e RecomendaÃ§Ãµes:
   - ForneÃ§a uma visÃ£o consolidada do mercado
   - Identifique qual ativo/timeframe apresenta melhor oportunidade
   - DÃª recomendaÃ§Ãµes priorizadas (qual operar primeiro)
   - Inclua nÃ­veis chave e gestÃ£o de risco global

Use formato:
## Imagem 1: [Ativo] [Timeframe]
- AnÃ¡lise tÃ©cnica resumida
- TendÃªncia, nÃ­veis, oportunidade

## Imagem 2: [Ativo] [Timeframe]
...

## AnÃ¡lise Comparativa
...

## RecomendaÃ§Ãµes PrioritÃ¡rias
...

Responda SEMPRE em portuguÃªs brasileiro de forma profissional."""
        )
        chat_client.with_model("openai", "gpt-5.1")
        
        # Send message with all images to AI
        user_msg = UserMessage(
            text=question,
            file_contents=image_contents
        )
        ai_response = await chat_client.send_message(user_msg)
        
        # Generate annotated images for both CALL and PUT scenarios
        annotated_image_paths = []
        call_annotated_paths = []
        put_annotated_paths = []
        
        try:
            annotator = ChartAnnotator()
            signals = annotator.extract_trading_signals(ai_response)
            
            # Generate both scenarios for each image
            for idx, (img_bytes, img_id) in enumerate(zip(original_image_bytes, image_ids)):
                try:
                    call_bytes, put_bytes = annotator.generate_both_scenarios(img_bytes, ai_response)
                    
                    # Save CALL annotated image
                    call_filename = f"{img_id}_call.png"
                    call_path = f"uploads/{call_filename}"
                    with open(call_path, "wb") as f:
                        f.write(call_bytes)
                    call_annotated_paths.append(f"/api/uploads/{call_filename}")
                    
                    # Save PUT annotated image
                    put_filename = f"{img_id}_put.png"
                    put_path = f"uploads/{put_filename}"
                    with open(put_path, "wb") as f:
                        f.write(put_bytes)
                    put_annotated_paths.append(f"/api/uploads/{put_filename}")
                    
                    # Add main annotated based on detected signal
                    if signals['action'] == 'PUT':
                        annotated_image_paths.append(f"/api/uploads/{put_filename}")
                    else:
                        annotated_image_paths.append(f"/api/uploads/{call_filename}")
                    
                    logging.info(f"Generated CALL and PUT images for image {idx + 1}")
                except Exception as e:
                    logging.error(f"Error annotating image {idx + 1}: {str(e)}")
                    annotated_image_paths.append(None)
                    call_annotated_paths.append(None)
                    put_annotated_paths.append(None)
        except Exception as e:
            logging.error(f"Error in annotation process: {str(e)}")
            import traceback
            logging.error(traceback.format_exc())
            # Continue without annotated images
        
        # Filter out None values
        filtered_annotated = [p for p in annotated_image_paths if p] if annotated_image_paths else None
        filtered_call = [p for p in call_annotated_paths if p] if call_annotated_paths else None
        filtered_put = [p for p in put_annotated_paths if p] if put_annotated_paths else None
        
        # Create assistant message with annotated image paths
        assistant_message = Message(
            role="assistant",
            content=ai_response,
            annotated_image_urls=filtered_annotated,
            call_annotated_urls=filtered_call,
            put_annotated_urls=filtered_put
        )
        
        # Save assistant message to database
        assistant_doc = assistant_message.model_dump()
        assistant_doc['timestamp'] = assistant_doc['timestamp'].isoformat()
        await db.messages.insert_one(assistant_doc)
        
        return MultipleImagesAnalysisResponse(
            image_ids=image_ids,
            image_paths=image_paths,
            annotated_image_paths=filtered_annotated,
            call_annotated_paths=filtered_call,
            put_annotated_paths=filtered_put,
            user_message=user_message,
            assistant_message=assistant_message
        )
        
    except HTTPException:
        raise
    except Exception as e:
        error_msg = str(e)
        logging.error(f"Error in multiple images analysis endpoint: {error_msg}")
        
        # Check if it's a budget error
        if "Budget has been exceeded" in error_msg or "budget" in error_msg.lower():
            raise HTTPException(
                status_code=402,  # Payment Required
                detail="âŒ OrÃ§amento da chave LLM excedido! Por favor, adicione crÃ©ditos em Profile -> Universal Key -> Add Balance"
            )
        
        raise HTTPException(status_code=500, detail=f"Error analyzing images: {error_msg}")


# Image generation endpoint
@api_router.post("/generate-image", response_model=ImageGenerationResponse)
async def generate_image(request: ImageGenerationRequest, x_custom_api_key: Optional[str] = Header(None)):
    try:
        # Use custom API key if provided
        api_key = x_custom_api_key if x_custom_api_key else os.environ['EMERGENT_LLM_KEY']
        
        # Initialize image generator
        image_gen = OpenAIImageGeneration(api_key=api_key)
        
        # Create user message
        user_message = Message(
            role="user",
            content=f"ðŸŽ¨ Gerar imagem: {request.prompt}"
        )
        
        # Save user message to database
        user_doc = user_message.model_dump()
        user_doc['timestamp'] = user_doc['timestamp'].isoformat()
        await db.messages.insert_one(user_doc)
        
        # Generate image
        images = await image_gen.generate_images(
            prompt=request.prompt,
            model="gpt-image-1",
            number_of_images=request.number_of_images
        )
        
        if not images or len(images) == 0:
            raise HTTPException(status_code=500, detail="Nenhuma imagem foi gerada")
        
        # Get first image
        image_bytes = images[0]
        
        # Convert to base64
        image_base64 = base64.b64encode(image_bytes).decode('utf-8')
        
        # Save image locally
        os.makedirs("uploads", exist_ok=True)
        image_id = str(uuid.uuid4())
        image_filename = f"{image_id}_generated.png"
        image_path = f"uploads/{image_filename}"
        
        with open(image_path, "wb") as f:
            f.write(image_bytes)
        
        # Create assistant message with generated image
        assistant_message = Message(
            role="assistant",
            content=f"âœ… Imagem gerada com sucesso a partir do prompt:\n\n**{request.prompt}**",
            image_urls=[f"/api/uploads/{image_filename}"]
        )
        
        # Save assistant message to database
        assistant_doc = assistant_message.model_dump()
        assistant_doc['timestamp'] = assistant_doc['timestamp'].isoformat()
        await db.messages.insert_one(assistant_doc)
        
        return ImageGenerationResponse(
            image_id=image_id,
            image_path=image_path,
            image_base64=image_base64,
            user_message=user_message,
            assistant_message=assistant_message
        )
        
    except HTTPException:
        raise
    except Exception as e:
        error_msg = str(e)
        logging.error(f"Error in image generation endpoint: {error_msg}")
        
        # Check if it's a budget error
        if "Budget has been exceeded" in error_msg or "budget" in error_msg.lower():
            raise HTTPException(
                status_code=402,  # Payment Required
                detail="âŒ OrÃ§amento da chave LLM excedido! Por favor, adicione crÃ©ditos em Profile -> Universal Key -> Add Balance"
            )
        
        raise HTTPException(status_code=500, detail=f"Error generating image: {error_msg}")


@api_router.get("/messages", response_model=List[Message])
async def get_messages():
    """Get all chat messages"""
    messages = await db.messages.find({}, {"_id": 0}).sort("timestamp", 1).to_list(1000)
    
    # Convert ISO string timestamps back to datetime objects
    for msg in messages:
        if isinstance(msg['timestamp'], str):
            msg['timestamp'] = datetime.fromisoformat(msg['timestamp'])
    
    return messages


@api_router.delete("/messages")
async def clear_messages():
    """Clear all chat messages"""
    result = await db.messages.delete_many({})
    return {"deleted_count": result.deleted_count}


@api_router.get("/")
async def root():
    return {"message": "Chat API is running"}


# Include the router in the main app
app.include_router(api_router)

# Mount static files for uploads directory under /api prefix (needed for proxy)
os.makedirs("uploads", exist_ok=True)
app.mount("/api/uploads", StaticFiles(directory="uploads"), name="uploads")

app.add_middleware(
    CORSMiddleware,
    allow_credentials=True,
    allow_origins=os.environ.get('CORS_ORIGINS', '*').split(','),
    allow_methods=["*"],
    allow_headers=["*"],
)

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

@app.on_event("shutdown")
async def shutdown_db_client():
    client.close()